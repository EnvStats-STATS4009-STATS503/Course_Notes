{
  "hash": "03358ab1c921a29729aa6ddb056d6a6a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab session 1\"\nformat: \n  html:\n    number-sections: true\n    toc: true\n    embed-resources: true\n  PrettyPDF-pdf:\n    keep-tex: true\n    number-sections: true\nembed-resources: true\neditor_options: \n  chunk_output_type: console\nbibliography: references.bib\nexecute: \n  freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n<font size=\"5\"> **Aim of this practical session:** </font>\n\nIn this first practical we are going\n\n-   To explore graphically some environmental data sets.\n-   To explore different estimation techniques for censored data (@sec-LoD).\n-   Design a monitoring network using the GRTS algorithm (@sec-design).\n\n\n\n\n\n\n{{< downloadthis lab_1.R dname=\"lab_1\" label = \"Download Lab 1 R script\" icon=\"database-fill-down\" type=\"success\" >}}\n\n\n\n\n\n\n\n\n\n\n# Task 1: Limits of detection {#sec-LoD}\n\nData reported at a limit of detection represent a common problem in environmental studies. For this problem, measurements on ammonia from a stretch of river will be studied, with 31% censored data. The data are available in the file `SiteSoar.csv`.\n\n\n\n\n\n\n{{< downloadthis datasets/SiteSoar.csv dname=\"SiteSoar\" label=\"Download data set\" icon=\"database-fill-down\" type=\"info\" >}}\n\n\n\n\n\n\n\n\n\n\nThe variables in the dataset are as follows:\n\n| Variable | Meaning |\n|------------------------------------|------------------------------------|\n| `year` | Year of observation |\n| `month` | Month of observation |\n| `day` | Day of observation (within month) |\n| `doy` | Day of observation (from start of year) |\n| `Ammonia` | Ammonia level |\n| `censored` | Censoring indicator (`FALSE`: no censoring; `TRUE`: censored at limit of detection) |\n\nHere we will consider three different methods of dealing with censored data (i.e., three strategies for replacement). These are:\n\n-   Kaplan-Meier estimates,\n-   Maximum Likelihood Estimators (MLEs), and\n-   Regression on Order Statistics (ROS). Note: ROS computes a linear regression for data (or their logs) versus their normal scores (from a Normal probability plot).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required R packages:\n\nlibrary(NADA)       # for analyzing censored observations\nlibrary(ggplot2)    # For visualizing our data\nlibrary(patchwork)  # For plotting multiple ggplot objects together\n\n# Read in data (making sure to set the working directory to the \n# appropriate location):\nSoar <- read.csv(\"datasets/SiteSoar.csv\", header = TRUE)\n\n# Examine structure of the dataset:\ndim(Soar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 224   6\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(Soar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t224 obs. of  6 variables:\n $ year    : int  1995 1995 1995 1996 2004 2003 2002 2002 2002 2000 ...\n $ month   : int  11 9 4 3 3 7 12 11 7 11 ...\n $ day     : int  21 30 24 20 24 24 22 13 25 2 ...\n $ doy     : int  326 274 115 80 84 206 357 318 207 307 ...\n $ Ammonia : num  0.064 0.03 0.03 0.049 0.03 0.03 0.174 0.115 0.03 0.091 ...\n $ censored: logi  FALSE TRUE TRUE FALSE TRUE TRUE ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Visualizing our data\n\nLets create some exploratory plots to visualize the relationship between Ammonia and time.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = Soar,aes(y = Ammonia, x = year))+geom_point()+\n  ggplot(data = Soar,aes(y = Ammonia, x = month))+geom_point()+\n  ggplot(data = Soar,aes(y = Ammonia, x = day))+geom_point()\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhat do you notice about the relationship between Ammonia and time? Do you notice any patterns or *unusual* observations?\n\n\n<div class='webex-solution'><button>See Solution</button>\n\n\nWe would like to focus here on the relationship between Ammonia and time. The key thing that we notice is the single point that has a high value of Ammonia. This seems like it could be an error rather than a true value (possibly a decimal point in the wrong place). We can also see this by looking at the dataset --- type `View(Soar)`.\n\nWe could justify removing the outlier, since its value is an order of magnitude larger than the other values, so is probably an error. We could alternatively justify not removing the outlier, since we would need to first consult a subject-matter expert before concluding that it was an unlikely value of Ammonia. (It's up to you which you choose, as long as you justify it. I might remove this value.)\n\nThere are no obvious trends or seasonal patterns in the data, from these plots.\n\n\n</div>\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task 1\n\nBy looking at the exploratory plots there seems to be an outlier given by an Ammonia value that is larger than 2. Suppose we want to remove this from any further analysis (provided we have reasonable justification to do it). Remove the outlier from the dataset, you can use the `filter()` function from the `dplyr` package to achieve this.\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nWe can use the `filter` function from `dplyr` to subset our data according to a logical statement. Load the `dplyr` library and type `?filter` for further details.\n\n\n</div>\n\n\n\n\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(dplyr)\n\nSoar <- Soar %>% filter(Ammonia <2)\n```\n\n\n</div>\n:::\n\n\n\n\n\n:::\n\nLets look into some further statistics using the `pctCen` and `censummary` functions from `NADA`:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Further summary statistics:\npctCen(Soar$Ammonia, Soar$censored)     ## percent of censored data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 31.39013\n```\n\n\n:::\n\n```{.r .cell-code}\ncensummary(Soar$Ammonia, Soar$censored) ## like summary cmd but for \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nall:\n        n     n.cen   pct.cen       min       max \n223.00000  70.00000  31.39013   0.01200   0.27000 \n\nlimits:\n  limit  n uncen   pexceed\n1  0.00  0    22 1.0000000\n2  0.03 70   131 0.5874439\n```\n\n\n:::\n\n```{.r .cell-code}\n                                        ## censored data\n```\n:::\n\n\n\n\n\n\n**What does this tell us?** You can ignore the limit of \"0.00\", since the function adds this by default if there is only one positive limit in the dataset --- you can see that `n` takes the value 0 here, meaning that there are no data points censored at 0.\n\nIn the first line, `uncen` tells us that there are 22 data points that have values between 0 and the LoD of 0.03, so this emphasises that just because we have a LoD in the data, that doesn't mean that all data points will be censored here, since different instruments (that have different LoDs) may have been used to generate the same dataset.\n\nIn the second line, we see that there are 70 data points censored at the LoD of 0.03. There are 131 data points that take values above 0.03. `pexceed` tells us that the probability of exceeding the LoD is $131/(131+70+22) = 0.589$.\n\n## Dealing with censored observations\n\n### ROS\n\nFirst, we will implement Regression on Order Statistics (ROS) using the `cenros` function\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1. ROS:\nROS <- cenros(Soar$Ammonia, Soar$censored) ## constructs an object of \n                                           ## class c(\"ros\", \"lm\")\nplot(ROS)    ## probability plot\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nplot(ROS, plot.censored = TRUE) ## plots the modelled censored \n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-6-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n**Interpretation of plot:** Here, do the filled black circles generally follow a straight line? Yes, so the model seems reasonable to use here.\n\nThe imputed values are the empty black circles, and these seem reasonable --- we have already seen that the model seems to be appropriate, so this should be the case.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ROS) ## more info about the ROS regression\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = obs.transformed ~ pp.nq, na.action = na.action)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23643 -0.09932 -0.00931  0.08775  0.51484 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3.21742    0.01090 -295.29   <2e-16 ***\npp.nq        0.81982    0.01175   69.75   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1194 on 151 degrees of freedom\nMultiple R-squared:  0.9699,\tAdjusted R-squared:  0.9697 \nF-statistic:  4866 on 1 and 151 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n`pp.nq` should be statistically significant --- it is (p \\< 0.05).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(ROS)   ## prints a simple summary of the ROS model.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           n        n.cen       median         mean           sd \n223.00000000  70.00000000   0.03600000   0.05577297   0.04960383 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nThis is what we really care about here --- this represents the summary of the censored data, with mean 0.056 and standard deviation 0.049. We'll use this to generate our imputed values later.\n\n### Kaplan-Meier\n\nNow lets look into the Kaplan-Meier\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 2. Kaplan-Meier:\nKM <- cenfit(Soar$Ammonia, Soar$censored)  ## constructs a Kaplan-Meier model\nplot(KM)   ## survival function plot\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\nOn the x-axis we have the Concentration values and on the y-axis we have the proportion of observations $\\neq$ to each concentration. Don't worry too much about the interpretation of this plot. It tells us about the probability of the data being at most a certain value (using the information that we have from the censored and uncensored data). What we are actually interestes is in the following output:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(KM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           n        n.cen       median         mean           sd \n223.00000000  70.00000000   0.03600000   0.05590147   0.04967880 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n### MLE\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 3. MLE\nMLE <- cenmle(Soar$Ammonia, Soar$censored) ## constructs a Maximum Likelihood model\nplot(MLE)\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhat can you tell about the plot above?\n\n\n<div class='webex-solution'><button>See Solution</button>\n\n\nMost of the points follow the fitted line, so this model appears appropriate. (We should not worry too much about the few points that lie far from the line --- this doesn't mean that our model is not appropriate.)\n\n\n</div>\n\n:::\n\nLets look into some summaries for the model\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(MLE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Value Std. Error      z       p\n(Intercept) -3.252     0.0612 -53.16 0.00000\nLog(scale)  -0.167     0.0604  -2.77 0.00559\n\nScale = 0.846 \n\nLog Normal distribution\nLoglik(model)= 189.9   Loglik(intercept only)= 189.9 \nLoglik-r:  0 \n\nNumber of Newton-Raphson Iterations: 5 \nn = 223 \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(MLE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           n        n.cen       median         mean           sd \n223.00000000  70.00000000   0.03871202   0.05536429   0.05660577 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Imputation\n\nFirst, lets compare the estimated mean and sd of each method. We can use the `censtats` function to achieve this:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncenstats(Soar$Ammonia, Soar$censored)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        n     n.cen   pct.cen \n223.00000  70.00000  31.39013 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        median       mean         sd\nK-M 0.03600000 0.05590147 0.04967880\nROS 0.03600000 0.05577297 0.04960383\nMLE 0.03871202 0.05536429 0.05660577\n```\n\n\n:::\n:::\n\n\n\n\n\n\nNow, lets create a function that draws a value between 0 and a given *LoD* based on a $\\mathrm{Normal}(\\mu,\\sigma)$ density.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfx_lod = function(lod,mean,sd) {\n    repeat {\n      x <- rnorm(1, mean, sd) # generate a value from N(mu,sigma)\n      if (x >= 0 && x <= lod) # repeat unless the generated value is >=0 and <LoD\n        return(x)   \n    }\n}\n```\n:::\n\n\n\n\n\n\nFor example taking the mean and sd from the ROS output and a $LoD = 0.3$ we have\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfx_lod(0.3,mean(ROS),sd(ROS))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05668802\n```\n\n\n:::\n:::\n\n\n\n\n\n\nNow we can input the censored values by applying the custom-built `fx_lod()` function using the estimated mean and variance from the ROS as follows:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSoar$imputed.ROS <- ifelse(\n  Soar$censored == F,\n  Soar$Ammonia,  # Keep original if not censored \n  # otherwise apply the fx_lod function for each censored observation\n  sapply(Soar$Ammonia[Soar$censored], fx_lod, mean = mean(ROS), sd = sd(ROS))\n)\n```\n:::\n\n\n\n\n\n\nLets visualize our results. We can plot the original and imputed Ammonia values against the day of the year as follows:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data=Soar,aes(y=Ammonia,x=doy,color=censored))+\n  geom_point() +\n  scale_color_discrete(name=\"Censored\")+\nggplot(data=Soar,aes(y=imputed.ROS,x=doy,color=censored))+\n  geom_point() + scale_color_discrete(name=\"Imputed\")\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-17-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\nInstead, we can create a decimal year or fractional year timestamp by combining the year with the day of year:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nSoar$year.day <- Soar$year + Soar$doy / 366\n\nggplot(data=Soar,aes(y=Ammonia,x=year.day,color=censored))+\n  geom_point() +\n  scale_color_discrete(name=\"Censored\")+\nggplot(data=Soar,aes(y=imputed.ROS,x=year.day,color=censored))+\n  geom_point() + scale_color_discrete(name=\"Imputed\")\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-18-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task 2\n\n1.  Add to other columns to the `Soar` data set names `Soar$imputed.KM` and `Soar$imputed.MLE` containing the imputed values for KM and MLE respectively.\n\n2.  Create three plots that compare the imputed ammonia values against the decimal year for each method. Discuss how changing the approach taken affects the imputed values.\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\n\n</div>\n\n\n\n\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nSoar$imputed.KM <- ifelse(\n  Soar$censored == F,\n  Soar$Ammonia,  # Keep original if not censored \n  # otherwise apply the fx_lod function for each censored observation\n  sapply(Soar$Ammonia[Soar$censored], fx_lod, mean = mean(KM), sd = sd(KM))\n)\n\nSoar$imputed.MLE <- ifelse(\n  Soar$censored == F,\n  Soar$Ammonia,  # Keep original if not censored \n  # otherwise apply the fx_lod function for each censored observation\n  sapply(Soar$Ammonia[Soar$censored], fx_lod, mean = mean(MLE), sd = sd(MLE))\n)\n\nggplot(data=Soar,aes(y=imputed.ROS,x=year.day,color=censored))+\n  geom_point() + \n  scale_color_discrete(name=\"Imputed\")+\n  ggtitle(\"ROS imputation\") +\nggplot(data=Soar,aes(y=imputed.KM,x=year.day,color=censored))+\n  geom_point() + \n  scale_color_discrete(name=\"Imputed\")+\n  ggtitle(\"KM imputation\") +\nggplot(data=Soar,aes(y=imputed.MLE,x=year.day,color=censored))+\n  geom_point() + \n  scale_color_discrete(name=\"Imputed\")+\n  ggtitle(\"MLE imputation\")\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-19-1.pdf){fig-pos='H'}\n:::\n\n\n</div>\n:::\n\n\n\n\n\n:::\n\n# Designing a monitoring network {#sec-design}\n\nSpatial sampling design is critical for ensuring monitoring data are representative and cost-effective. This practical introduces **generalized random-tessellation stratified (GRTS) sampling** using the `spsurvey` package in R. GRTS provides spatially balanced samples—avoiding clustering while ensuring geographic coverage—and is widely used in environmental monitoring programs. We will design a monitoring network for lakes in the Northeastern US. The `NE_Lakes` dataset contains the spatial information of 195 lakes in the Northeastern United States which are summarised in the following table:\n\n| Variable | Meaning |\n|------------------------------------|------------------------------------|\n| AREA | Lake area in hectares. |\n| AREA_CAT | Lake area categories based on a hectare cutoff. |\n| ELEV | Elevation in meters. |\n| ELEV_CAT | Elevation categories based on a meter cutoff. |\n| geometry | POINT geometry using the NAD83 / Conus Albers coordinate reference system (EPSG: 5070) |\n\nWe begin by first loading the data set contained within the `spsurvey` package, additionally we will load the `mapview` and `sf` packages for visualizing our data.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(spsurvey)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spsurvey' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: sf\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: survey\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'survey' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: grid\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: Matrix\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'survey'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:graphics':\n\n    dotchart\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(mapview)\ndata(\"NE_Lakes\")\n```\n:::\n\n\n\n\n\n\nThe `NE_Lakes` data is a Simple Features (`sf`) object containing the spatial information for the point-location of 195 lakes in the Northeastern United States. We can use the `mapview` function to visualise the distribution of lakes as follow:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(NE_Lakes,zcol=\"AREA_CAT\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:///C:/Users/admin/AppData/Local/Temp/RtmpK6G9Kk/file1f08673f730/widget1f0858836403.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-21-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task 3\n\nIn the previous plot we have shown the spatial distribution of lakes colored by their size. Create a map that shows the lake distribution colored by low and high elevation levels. Do you see any patterns?\n\n\n\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nmapview(NE_Lakes,zcol=\"ELEV_CAT\")\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n\n\n</div>\n:::\n\n\n\n\n\n:::\n\n## Independent  Random Sampling\n\nSuppose we want to select a random sample of 50 lakes using independent random sampling without replacement. To do so we can use the `irs` function from `spsurvey` to draw a random sample of size 50 with equal probabilities as follows:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neqprob_irs <- irs(NE_Lakes, n_base = 50)\n```\n:::\n\n\n\n\n\n\nTo visualize the selected sites (lakes) we can use the `sf` library and `ggplot` packages:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data=NE_Lakes,aes(color=\"Not Selected\")) +\n  geom_sf(data=eqprob_irs$sites_base,aes(color=\"Selected\"))\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-24-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## GRTS with equal inclusion probabilities\n\nNow, we will implement the GRTS algorithm using the `grts()` function to select a spatially balanced sample of size 50 where each lake has an equal inclusion probability,\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neqprob <- grts(NE_Lakes, n_base = 50)\n```\n:::\n\n\n\n\n\n\nYou can either, `mapview` (interactive map), `ggplot()` (static map) or the R base `plot()` functions to visualize the selected site for monitoring.\n\n::: panel-tabset\n## Base R `plot()`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(eqprob)\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-26-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## `ggplot` and `sf`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data=eqprob$sites_base)\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-27-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## `mapview`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(eqprob$sites_base)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:///C:/Users/admin/AppData/Local/Temp/RtmpK6G9Kk/file1f0813dc3acf/widget1f086406561e.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-28-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n:::\n\n## GRTS with statified sampling\n\nInstead of sampling from the entire sampling area simultaneously, we can apply the GRTS algorithm for a given strata and select samples from each stratum independently of other strata.\n\nIn this example we will obtain a GRTS sample stratified by the lake elevation categories where all lake within a stratum have equal inclusion probabilities:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_strata <- c(low = 35, high = 15)\n\neqprob_strat <- grts(NE_Lakes, n_base = n_strata,\n                     stratum_var = \"ELEV_CAT\")\n```\n:::\n\n\n\n\n\n\nHere,`n_strata` specifies the stratum-specific sample sizes (35 for low elevation category and 15 for the high elevation category). Notice that the names in `n_strata` (low and high) need to match the names of the stratification variable (`\"ELEV_CAT\"`) in the `NE_Lakes` data. The the `grts` function receives as arguments the `n_strata` vector and name of the column in the data that represents the stratification variable via the `stratum_var` argument.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(eqprob$sites_base,\n        map.types = c(\"Esri.WorldShadedRelief\"),\n        col.regions = \"tomato\",\n        layer.name=\"GTRS sampling\")+\nmapview(eqprob_strat$sites_base,\n        map.types = c(\"Esri.WorldShadedRelief\"),\n        col.regions = \"purple\",\n        layer.name=\"Stratified GTRS sampling\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:///C:/Users/admin/AppData/Local/Temp/RtmpK6G9Kk/file1f087773376/widget1f0874bf5482.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-30-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## GRTS with unequal inclusion probabilities\n\nSometimes we don't want inclusion probabilities to be equal for all sites. For example, we may want larger lakes to be sampled more frequently than smaller lakes based on attributes like surface area.\n\nThe `caty_n` and `caty_var` arguments in the `gtrs` functions allows us to select a GRTS sample with unequal inclusion probabilities according to a particular category e.g., lake area.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaty_n <- c(small = 10, large = 40)\nuneqprob <- grts(NE_Lakes, n_base = 50, caty_n = caty_n, caty_var = \"AREA_CAT\")\n```\n:::\n\n\n\n\n\n\nThe `cat_n` vector specifies the within-level sample sizes. This gets passed on to `grts` via the `caty_n` argument. The names in `caty_n` must match the different levels of categorical variable which in the data (specified via the `caty_var` argument).\n\nThe map below shows a sample size of 40 for large lakes and sample size of 10 small lakes.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(uneqprob$sites_base,\n        zcol=\"AREA_CAT\",\n        map.types = c(\"Esri.WorldShadedRelief\"),\n        layer.name=\"GTRS sampling with unequal inclusion probabilities\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:///C:/Users/admin/AppData/Local/Temp/RtmpK6G9Kk/file1f0828d91310/widget1f08fbc4734.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-32-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\nWe can also implement probability proportional to size (PPS) sampling, where each lake's selection probability is directly proportional to its surface area. This avoids arbitrary size categories and ensures larger lakes—which often have greater ecological and socioeconomic importance—are more likely to be selected. We can conduct PPS sampling by specifying the lake's areas as an `aux_var` variable in the `grts()` function:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npropprob <- grts(NE_Lakes, n_base = 50, aux_var = \"AREA\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(propprob$sites_base,\n                zcol=\"AREA\",\n        map.types = c(\"Esri.WorldShadedRelief\"),\n        layer.name=\"GTRS sampling with PPS sampling\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:///C:/Users/admin/AppData/Local/Temp/RtmpK6G9Kk/file1f0836b71d43/widget1f081abb5a6e.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-34-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## Additional features in `spsurvey`\n\nOther useful features that have been implemented on the `grts` function are (see @dumelle2023 for a more comprehensive description of the package):\n\n-   *Legacy sites* - allows sites selected from a previous sampling scheme to be selected in a new sample (`grts(NE_Lakes, n_base = 50,legacy_sites = NE_Lakes_Legacy)`). This is often used to study or monitor the behavior of the sites in the network through time.\n\n-   *Minimum distance selection* -Sometimes the selected sites are too close to each other. We can set a minimum distance between sites by setting the `mindis` argument to a particular distance determined by the data CRS (e.g., `grts(NE_Lakes, n_base = 50, mindis = 1600)`)\n\n-   *Replacement sites* - it is common that once a network has been designed the data at some of the selected in the sample not able to been able to collected at the site(e.g, due terrain contraints or landowner permission). We can then use a nearest neighbor approach to selects replacement sites according to the distance between GRTS-sampled site and all other sites in the sampling frame that are not part of the GRTS sample. E.g., to select a GRTS sample of size 50 with two nearest neighbor replacement we can run `eqprob_nn <- grts(NE_Lakes, n_base = 50, n_near = 2)`.\n\n## Assessing spatial balance\n\nA practical way to measure spatial balance was developed by @stevens2004 using Voronoi polygons. In this approach, each sampled site defines a region containing all locations closer to it than to any other sampled site. For a spatially balanced design, the total inclusion probability of all sites within each Voronoi polygon is expected to be 1. Deviation from this ideal can be quantified using a loss metric based on these polygon totals. One common choice is Pielou's evenness index (PEI), which assesses how uniformly the inclusion probability is distributed across the sample sites. Pielou’s evenness index (PEI) is defined as:\n\n$$\n\\text{PEI} = 1 + \\frac{\\sum_{i=1}^{n} \\frac{v_i}{n} \\ln(v_i/n)}{\\ln(n)},\n$$\n\nwhere $n$ is the sample size. PEI is bounded between zero and one. A PEI of zero indicates perfect spatial balance. As PEI increases, the spatial balance worsens. The `sp_balance()` function which receives as arguments the (i) design sites and (ii) the sampling frame ( note that if stratified sampling is being compared you also need to supply the name of the stratified variable in your data via the `stratum_var` arugment).\n\nthe following code compares the GRTS with equal inclusion probabilities again the SRS:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsp_balance(eqprob$sites_base, NE_Lakes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  stratum metric      value\n1    None pielou 0.02348388\n```\n\n\n:::\n\n```{.r .cell-code}\nsp_balance(eqprob_irs$sites_base, NE_Lakes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  stratum metric     value\n1    None pielou 0.0376794\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\nWhich design has better spatial balance?\n\n\n\n* (A) SRS  \n* (B) GRTS  \n\n\n\n:::\n\n\nSo far we have applied the GRTS algorithm to point reference data. However, this methodology can also be applied on linear and areal data in similar fashion – the only difference being the geometry type of the `sf` object used as argument.  In the next exercise you will be tasked to design a river network using GRTS algorithm for a section of the llinois River in Arkansas and Oklahoma.\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task 4\n\nThe  `Illinois_River` data in `spsurvey` contains the spatial information of 244 segments of the Illinois River in Arkansas and Oklahoma. The data can be accessed with `data(Illinois_River)`. Use the `grts` to:\n\n1. Design a monitoring network with $n=25$ sampling points using *simple random sampling*.\n\n2. Design a monitoring network with $n=25$ sampling points using *GRTS sampling* with equal inclusion probabilities.\n\n3. Plot both sampling designs using `ggplot2`, coloring the selected sites according to the sampling method.\n\nFinally, compare the spatial balance of the two approaches. Which method provides better spatial coverage across the river network?\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nYou can add multiple `geom_sf()` layers to a ggplot object, e.g., \n\n```r\nggplot()+\ngeom_sf(data=layer_1)+\ngeom_sf(data=leayer_2) +...\n```\n\n\n</div>\n\n\n\n\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\ndata(Illinois_River)\n\nirs_linear <- irs(Illinois_River, n_base = 25)\neqprob_linear <- grts(Illinois_River, n_base = 25)\n\nggplot()+\n  geom_sf(data=Illinois_River,color=\"gray40\")+\n  geom_sf(data=eqprob_linear$sites_base,aes(color=\"GRTS sampled sites\"))+\n  geom_sf(data=irs_linear$sites_base,aes(color=\"IRS sampled sites\"))\n```\n\n::: {.cell-output-display}\n![](lab_1_files/figure-pdf/unnamed-chunk-36-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\nsp_balance(irs_linear$sites_base, Illinois_River)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  stratum metric      value\n1    None pielou 0.04926403\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\nsp_balance(eqprob_linear$sites_base, Illinois_River)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  stratum metric      value\n1    None pielou 0.02844077\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\n# GRTS PEI is smaller and thus provided a better spatially balanced design\n```\n\n\n</div>\n:::\n\n\n\n\n\n:::\n",
    "supporting": [
      "lab_1_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}