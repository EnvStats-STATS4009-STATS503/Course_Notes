{
  "hash": "5321b08edcbb63c378f87d8ef9193bf8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding our Data\"\nembed-resources: true\nformat:\n  revealjs:\n    footer: '<a href=\"https://envstats-stats4009-stats503.github.io/Course_Notes/2025_26/Module_1/docs/\" style=\"color:#ccc; padding:20px 30px; display:inline-block; margin:-20px -30px;\">Home</a>'\n    margin: 0\n    logo:  UofG.png\n    theme: uofg_theme.scss\n    header-includes: |\n      <script src=\"custom.js\" type=\"application/javascript\"></script>\ntitle-slide-attributes: \n  data-background-image: uog_cloistures2.jpg\n  data-background-color: \"#FFFFFF\"\nslide-number: true\ninclude-in-header: \n  text: |\n    <style>\n      .custom-small table {\n        font-size: .8em\n      }\n      .custom-tiny table {\n        font-size: .6em\n      }\n    </style>\nauthor:\n  - name: Jafet Belmont \n    email: jafet.BelmontOsuna@glasgow.ac.uk \n    affiliations: School of Mathematics and Statistics\neditor_options: \n  chunk_output_type: console\nexecute: \n  eval: true\n  echo: true\n  allow-html: true\n  freeze: auto\n---\n\n## Understanding our Data\n\n-   Last week we introduced some of the key motivations behind Environmental Statistics.\n\n-   The course will cover a number of statistical ideas around the general theme of environmental data.\n\n-   This week we will be looking at uncertainty and variability, and how we can measure these and incorporate them into our conclusions.\n\n-   We will then look at a number of important features of environmental data --- censoring, outliers and missing data.\n\n# Uncertainty and Variability\n\n## Uncertainty and Error {.smaller}\n\n-   We often talk about uncertainty and error as though they are interchangeable, but this is not quite correct.\n\n-   **Error** is the difference between the measured value and the \"*true value*\" of the thing being measured.\n\n-   **Uncertainty** is a quantification of the variability of the measurement result.\n\n-   Practically speaking, we make use of common statistical distributions to account for uncertainty.\n\n![](figures/system_vsranerr.png){fig-align=\"center\" width=\"693\"}\n\n## Recap: Continuous Distributions {.smaller background-color=\"#FFFFFF\"}\n\n::::::::: panel-tabset\n## Normal density\n\n::::: columns\n::: {.column width=\"40%\"}\nA continuous random variable $X$ follows a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ if its probability density function (pdf) is:\n\n$$\n        f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n$$\n\nWe denote this as:\n\n$$\n        X \\sim \\mathcal{N}(\\mu, \\sigma^2), ~\\text{where} ~ -\\infty < X < +\\infty\n$$\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n:::\n:::::\n\n*Why can't we just use normal distributions for all environmental data?*\n\n## log-Normal density\n\nA random variable $X$ follows a log-normal distribution if $\\ln(X)$ follows a normal distribution,i.e.\n\n$$\n        Y = \\ln(X) \\sim \\mathcal{N}(\\mu, \\sigma^2) \\quad  \\text{where}~ Y\\in (0, +\\infty)\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## Exponential\n\n::::: columns\n::: {.column width=\"40%\"}\nA random variable $X$ follows an exponential distribution with rate parameter $\\lambda >0$ if its probability density function (pdf) is:\n\n$$\nf(x; \\lambda) = \n\\begin{cases} \n\\lambda e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\ \n0 & \\text{for } x < 0 \n\\end{cases}\n$$\n\n$\\lambda$ describes the rate of events, i.e., the no. of events per unit time/distance\n\n-   Higher $\\lambda$ = more frequent events\n-   Mean waiting time: $E[X] = \\frac{1}{\\lambda}$ (e.g., $\\lambda = 0.2$ rainfall events/hour $\\rightarrow$ Mean time between events = 5 hours)\n-   Variance: $Var(X) = \\frac{1}{\\lambda^2}$\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n:::\n:::::\n:::::::::\n\n## Recap: Discrete Distributions {.smaller background-color=\"#FFFFFF\"}\n\n:::::::::::: panel-tabset\n## Poisson density\n\n::::: columns\n::: {.column width=\"50%\"}\nA discrete random variable $X$ follows a Poisson distribution with rate parameter $\\lambda > 0$ if its probability mass function (PMF) is:\n\n$$\nP(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, ~ k = 0, 1, \\dots\n$$\n\nWe denote this as $X \\sim Po(\\lambda)$ where $\\lambda$ describes:\n\n-   Expected number of events in a fixed interval\n-   Mean events per unit time/area/volume\n-   Example: $\\lambda = 3.2$ means 3.2 events expected on average\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n:::::\n\n## Binomial density\n\n::::: columns\n::: {.column width=\"55%\"}\nA discrete random variable $X$ follows a binomial distribution with parameters $n$ and $p$ if:\n\n$$\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\quad k = 0, 1, 2, \\dots, n\n$$\n\nWe denote this as $X \\sim Bi(n, p)$ where:\n\n-   $n$ = number of independent trials\n\n-   $p$ = probability of success in each trial\n\n-   $k$ = number of successes observed\n\n**Survival studies:** $n$ animals, each with survival probability $p$\n\n**Detection/non-detection:** $n$ surveys, probability $p$ of detecting species\n:::\n\n::: {.column width=\"45%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-5-1.png){width=384}\n:::\n:::\n\n:::\n:::::\n\n## Negative-Binomial density\n\n::::: columns\n::: {.column width=\"55%\"}\nA discrete random variable $X$ follows a negative binomial distribution with parameters $r$ and $p$ if:\n\n$$\nP(X = k) = \\binom{k + r - 1}{k} (1-p)^r p^k, ~ k = 0, 1, \\dots\n$$\n\nThe distribution of the number of trials until the $r$th success is denoted by $X\\sim \\mathrm{NegBi}(r,p)$ Where\n\n-   $r$ = number of failures\n-   $p$ = probability of success on each trial\n-   $k$ = number of successes\n:::\n\n::: {.column width=\"45%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_2_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n:::\n:::::\n::::::::::::\n\n## Example: Bathing Water Quality\n\n-   All bathing water sites in Scotland are classified [**by SEPA**](https://bathingwaters.sepa.scot/) as \"Excellent\", \"Good\", \"Sufficient\" or \"Poor\" in terms of how much faecal bacteria (from sewage) they contain.\n\n-   The minimum standard all beaches or bathing water must meet is \"Sufficient\".\n\n-   The sites are classified based on the 90th and 95th percentiles of samples taken over the four most recent bathing seasons.\n\n::: notes\nNote: SEPA = Scottish Environment Protection Agency The classification uses percentiles because water quality can be highly variable - we care about the worst-case scenarios (90th/95th percentiles), not just average conditions.\n:::\n\n## Example: Bathing Water Quality\n\n![Green is [excellent]{style=\"color:green;\"} , [blue]{style=\"color:blue;\"} is good, red is [sufficient]{style=\"color:red;\"}](figures/BathingWater.png){fig-align=\"center\"}\n\n## Example: bathing water quality\n\n-   The classification system assumes that bacterial concentrations at each site follow a **log-normal distribution**.\n\n-   If this assumption does **not** hold, the classifications would **not be accurate**.\n\n-   Therefore, it is **crucial** that we regularly assess this assumption to ensure the safety of our bathing water.\n\n## Example: bathing water quality\n\n::::: columns\n::: {.column width=\"60%\"}\n![](figures/WaterNormality1.png){fig-align=\"center\"}\n\n![](figures/WaterNormality2.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"40%\"}\n-   We can use our standard residual plots to assess log-normality.\n\n-   The top plots show the standard residuals and the bottom plots show the residuals for the log-transformed data.\n\n-   There is **no strong** evidence to suggest we have breached our assumptions.\n:::\n:::::\n\n\n## Error in Environmental Measurements\n\n**Error** in a measurement is the difference between the measured value and the true value.\n\n- Error may include both **random** and **systematic** components.\n\n**Random error**: Variation observed randomly over repeat measurements.  \n→ With more measurements, these errors average out (improves accuracy).\n\n\n\n## Systematic Error\n\n**Systematic error**: Variation that remains constant over repeated measures.\n\n- Typically due to some feature of the measurement process.\n- Making more measurements **will not improve accuracy** (all affected equally).\n- Can only be eliminated by identifying and correcting the cause.\n\n\n## Error Identification Exercise\n\nFor each example, identify whether the error is **random** or **systematic**:\n\n1. **A meter reads 0.01 even when measuring no sample.**  \n   → *Hint: Constant offset regardless of measurement...*\n\n2. **An old thermometer can only measure to the nearest 0.5 degrees.**  \n   → *Hint: Precision limitation...*\n\n3. **A poorly designed rainfall monitor often leaks water on windy days.**  \n   → *Hint: Specific condition causing consistent bias...*\n\n4. **To estimate the abundance of a fish species in a lake, scientists use a net with a mesh size equal to the average fish length**  \n   → *Hint: Only fishes up to a given size can be caught *\n\n**Discuss with a neighbor!**\n\n---\n\n## Answers & Discussion\n\n1. **Systematic** - Constant offset (bias)\n2. **Random** - Precision limitation (rounding error varies)\n3. **Systematic** - Consistent bias under specific conditions\n4. **Systematic** - All measurements affected by melting\n\n**Key takeaway**: Random errors can be reduced by averaging; systematic errors require calibration, better instruments, or method changes.\n\n\n",
    "supporting": [
      "slides_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}