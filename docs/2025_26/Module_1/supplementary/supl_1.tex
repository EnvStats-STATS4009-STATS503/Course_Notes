% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Supplementary Notes},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Supplementary Notes}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Estimator properties}
\author{}
\date{}

\begin{document}
\maketitle


In this section we recap some important statistical properties of our
estimators (for further details please refer to the statistical
inference course).

A population parameter \(\theta\) represents a quantitative measurement
of population values. Since \(\theta\) is typically unknown, we need to
estimate it by drawing samples from the population of interest. Our
estimator, \(\hat{\theta}\),is then computed based on the samples we
have obtained. The question is then, how well does \(\hat{\theta}\) do
its job in estimating \(\theta\)? To evaluate this, we examine key
statistical properties of estimators.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{supl_1_files/figure-pdf/fig-sampling1-1.pdf}}

}

\caption{\label{fig-sampling1}Sampling from Normal Distribution. The
black curve represent the true population distribution with mean
represented by the black solid line. The colored point are two different
samples with their corresponding sample mean shown in colured dashed
lines.}

\end{figure}%

\textbf{Consistency}

As we see in Figure~\ref{fig-sampling1}, there is some discrepancy
between the sample means and the true population mean. Thus, it is
expected that, as the sample size increases, our estimator
\(\hat{\theta}\) will get closer to the true value \(\theta\). Thus an
estimator \(\hat{\theta}\) is said to be \emph{consistent} if it
converges to the true parameter \(\theta\) as the sample size \(n\)
increases, i.e., \(\hat{\theta} \rightarrow \theta\) as \(n\to\infty\).
E.g., let \(\hat{\theta} = \bar{x} + \frac{1}{n}\) be a biased but
consistent estimator of \(\theta = 5\) (\(\bar{x}\) represents the
sample mean). Figure~\ref{fig-sampling2} shows how as sample size
increases, the estimator converges to the true parameter.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{supl_1_files/figure-pdf/fig-sampling2-1.pdf}}

}

\caption{\label{fig-sampling2}Demonstration of estimator consistency.
The dashed red line indicates the true parameter value. The blue line
tracks the mean estimate across increasing sample sizes, while the
shaded region represents the 95\% confidence interval.}

\end{figure}%

\textbf{Expected value}

The expected value of an estimator is a weighted average of all possible
estimates. Here, the weights are given by the probability of selecting a
particular sample \(s\), i.e., \(p(s)\). Mathematically, this can be
written as:

\[
\mathbb{E}(\hat{\theta})= \sum_{x\in\Omega} p(s)\hat{\theta(s)}
\]

Where \(\Omega\) is the sample space, i.e.~the number of possible
samples. Furthermore, if all possible samples are equally likely then
\(p(s)=\frac{1}{\Omega}\) and the expected values becomes:

\[
\mathbb{E}(\hat{\theta}) = \dfrac{1}{\Omega} \sum_{s\in\Omega} \hat{\theta}(s).
\]

Note that the expected value is a function of both, the sampling design
(due to \(p(s)\)) and the population being sampled (through the sample
estimate \(\hat{\theta}(s)\)).

\begin{tcolorbox}[enhanced jigsaw, titlerule=0mm, rightrule=.15mm, coltitle=black, bottomtitle=1mm, left=2mm, colback=white, colframe=quarto-callout-important-color-frame, toptitle=1mm, arc=.35mm, title={Task 1}, opacitybacktitle=0.6, bottomrule=.15mm, breakable, toprule=.15mm, leftrule=.75mm, opacityback=0, colbacktitle=quarto-callout-important-color!10!white]

Suppose we have a tiny population of three trees with the following
diameters (cm) :

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Tree & diameter (cm) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 9.1 \\
2 & 10.2 \\
3 & 17.2 \\
\end{longtable}

Now, we sample only \textbf{2 trees} and measure the diameter of each
tree in the sample. It is clear from here that there are only
\(\Omega=3\) possible samples we could've taken:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(s_1 = \{\text{tree 1},\text{tree 2}\}\)
\item
  \(s_2 = \{\text{tree 1},\text{tree 3}\}\)
\item
  \(s_3 = \{\text{tree 2},\text{tree 3}\}\)
\end{enumerate}

Imagine that samples are selected with an equal probability so that
\(p(s_1) = p(s_2) = p(s_3) = 1/3\).

The true population mean diameter is
\(\mu_y = ( 9.1+10.2+ 17.2)/3 =12.17\).

Suppose we chose the sample average \(\bar{y}\) as our estimate of
\(\mu_y\). Then, the expected value of \(\bar{y}\) is given by

\[
\begin{aligned}\mathbb{E}(\bar{y}) &= p(s_1) \left(\dfrac{9.1+10.2}{2}\right) +  p(s_2) \left(\dfrac{9.1+17.2}{2}\right) +  p(s_3) \left(\dfrac{10.2+17.2}{2}\right)\\&= \dfrac{1}{3}\left(\dfrac{19.3}{2} + \dfrac{26.3}{2} + \dfrac{27.4}{2} \right)\\&= 12.17 = \mu_y\end{aligned}
\]

What would have happened if our sampling design had unequal sampling
probabilities given by \(p(s_1) = 1/2\), \(p(s_2) = 1/3\) and
\(p(s_3) = 1/6\)? Calculate \(\mathbb{E}(\hat{y})\) under this sampling
scenario.

See Solution

\[
\begin{aligned}
\mathbb{E}(\bar{y}) &= p(s_1) \left(\dfrac{9.1+10.2}{2}\right) +  p(s_2) \left(\dfrac{9.1+17.2}{2}\right) +  p(s_3) \left(\dfrac{10.2+17.2}{2}\right)\\
&= \dfrac{1}{2}\left(\dfrac{19.3}{2} \right) + \frac{1}{3} \left(\dfrac{26.3}{2}\right) + \dfrac{1}{6}\left(\dfrac{27.4}{2} \right)\\
&= \dfrac{19.3}{4}  + \dfrac{26.3}{6} + \dfrac{27.4}{12} \\
&= 11.5 \neq \mu_y
\end{aligned}
\]

\end{tcolorbox}

In practice, \(\mathbb{E}(\hat{\theta})\) cannot be evaluated because we
can not measure all the \(N\) elements of our population of interest!
(and if we could then \(\theta\) could be evaluated directly on our
population rather than obtaining a samples from it). However,
understanding this concept is important for two other relevant
quantities.

\textbf{Bias}

The bias of an estimator is the difference in magnitude between its
expected value and the population parameter for which an estimated is
desired:

\[
\textbf{Bias}(\hat{\theta}) = \mathbb{E}(\hat{\theta}) - \theta
\]

When \(\mathbb{E}(\hat{\theta}) = \theta\) , \(\hat{\theta}\) is said to
be an \emph{unbiased estimator} of \(\theta\).

Note that the bias is not a property of an individual estimate (e.g.,
\(\hat{\theta}(s)\)). E.g., we can see in Figure~\ref{fig-sampling1}
there are some discrepancies between the true population parameter
\(\theta\) and the sample estimates \(\hat{\theta}(1)\) and
\(\hat{\theta}(2)\). Such discrepancies \(\hat{\theta}(s) - \theta\) are
known as \emph{sampling errors}. This doesn't mean that an error has
been made during the sampling, it just indicates that the value being
estimated will differ from the true value because is being estimated
from just a fraction of the elements of the population. Thus, one may
wonder how much an estimate \(\hat{\theta}\) from one sample will differ
from that calculated from a different sample. In principle we would like
this difference to be small because that will ensure that no matter
which sample we take, the estimated value will be similar across
samples.

\textbf{Variance}

The \textbf{variance} of an estimator or \emph{sampling variance} is the
average squared distance between individual estimates
\(\hat{\theta}(s)\) and their expected value
\(\mathbb{E}(\hat{\theta})\), i.e.,

\[
\text{Var}(\hat{\theta}) = \sum_{s\in \Omega} p(s) \left(\hat{\theta}(s)-\mathbb{E}(\hat{\theta})\right)^2 
\] Notice how the variance of an estimator does not depend (unlike the
bias) on the true parameter \(\theta\)

\begin{tcolorbox}[enhanced jigsaw, titlerule=0mm, rightrule=.15mm, coltitle=black, bottomtitle=1mm, left=2mm, colback=white, colframe=quarto-callout-important-color-frame, toptitle=1mm, arc=.35mm, title={Task 2}, opacitybacktitle=0.6, bottomrule=.15mm, breakable, toprule=.15mm, leftrule=.75mm, opacityback=0, colbacktitle=quarto-callout-important-color!10!white]

Using the data from the previous task and assuming equal sampling
probabilities, calculate \(\text{Var}(\hat{y})\)

See Solution

\[
\begin{aligned}
\text{Var}(\bar{y}) &= p(s_1) \left(\dfrac{19.3}{2} - 12.17\right)^2 +  p(s_2) \left(\dfrac{26.3}{2} - 12.17\right)^2 +  p(s_3) \left(\dfrac{27.4}{2} - 12.17\right)^2\\
&= \dfrac{1}{3}\left(  9.65 \right) =  3.22 
\end{aligned}
\]

\end{tcolorbox}

\textbf{Precision}

The \textbf{precision} of an estimator is a qualitative measurement that
assess how small or large the variability of an estimator is and does
not relate to the true value. To illustrate this, suppose we draw 20
random samples with equal probability from our population of interest .
The figure below shows 100 replicates/data sets of this experiment with
4 different estimators:

\begin{itemize}
\item
  \(\hat{\theta}_{1}(s) =\frac{1}{20}\sum_{i=1}^{20} x_i\) - the mean of
  the \(s\)th sample which is \textbf{unbiased} and \textbf{precise}
\item
  \(\hat{\theta}_{2}(s) = \text{arg min } (x_1,\ldots, x_{20})\) - the
  \(s\)th sample minimum value which is \textbf{biased} and
  \textbf{imprecise}.
\item
  \(\hat{\theta}_{3}(s)  = x_1\) - the first observation of the
  unordered sample which is \textbf{unbiased} and \textbf{imprecise.}
\item
  \(\hat{\theta}_{4}(s) =2 + \frac{1}{20}\sum_{i=1}^{20} x_i\) - the
  mean + constant which is \textbf{biased} but \textbf{precise}.
\end{itemize}

Imagine a dartboard where the bullseye represents the true population
parameter (\(\theta\)). Each throw corresponds to a sample estimate
(\(\hat{\theta}(s)\)). Precision refers to how tightly clustered the
darts are - a precise estimator produces estimates that land close
together, regardless of their position relative to the bullseye. Bias,
on the other hand, is the systematic offset from the bullseye - even
with perfect precision, a biased estimator would consistently miss the
center in the same direction.

\begin{center}
\includegraphics[width=4.30208in,height=\textheight,keepaspectratio]{images/bias_prec2.png}
\end{center}




\end{document}
